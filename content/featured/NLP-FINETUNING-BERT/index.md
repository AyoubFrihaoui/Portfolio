---
date: '3'
title: 'NLP - Fine-tuning BERT'
cover: './image.png'
external: 'https://github.com/AyoubFrihaoui/Natural-Language-Processing-Labs/blob/master/Lab%203%20-%20Enhancing%20Lab%202/NLP%20LAB%203%20REPORT.pdf'
cta: 'https://github.com/AyoubFrihaoui/Natural-Language-Processing-Labs/blob/master/Lab%203%20-%20Enhancing%20Lab%202/NLP%20LAB%203%20REPORT.pdf'
tech:
  - Python
  - Tensorflow
  - Transformers
  - BERT
---

Fine-tuning BERT: Instead of relying solely on extracted features, Lab 3 employed
transfer learning by fine-tuning a pre-trained BERT model. This leveraged BERT's
ability to capture contextualized word representations and inherent language
understanding.
